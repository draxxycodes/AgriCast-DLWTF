<h1 align="center">ğŸŒ¾ AgriCast: Agricultural Commodity Price Prediction</h1>

<p align="center">
  <b>Deep Learning with TensorFlow - CSE 3793 Major Assignment</b>
</p>

<p align="center">
  <a href="#-quick-start"><img src="https://img.shields.io/badge/Quick%20Start-Guide-blue?style=for-the-badge" alt="Quick Start"/></a>
  <a href="#-model-architectures"><img src="https://img.shields.io/badge/Models-10%20Architectures-green?style=for-the-badge" alt="Models"/></a>
  <a href="#-results"><img src="https://img.shields.io/badge/Best%20RMSE-634.74-orange?style=for-the-badge" alt="Best RMSE"/></a>
  <a href="#-gpu-configuration"><img src="https://img.shields.io/badge/GPU-RTX%204060-red?style=for-the-badge" alt="GPU"/></a>
</p>

<p align="center">
  An <b>industry-grade intelligent system</b> for predicting agricultural commodity prices using <b>10 advanced deep learning architectures</b> including LSTM, GRU, Transformer, TCN, WaveNet, N-BEATS, TFT, ConvLSTM, DenseNN, and Attention models with <b>350+ million total trainable parameters</b>.
</p>

<p align="center">
  <img src="outputs/figures/comparison/05_radar_chart.png" alt="Model Performance Radar Chart" width="600"/>
</p>

---

## ğŸ“Š Performance Overview

### ğŸ† Model Leaderboard

| Rank | Model | RMSE â†“ | MAE | MAPE | RÂ² Score | Parameters |
|:----:|:------|-------:|----:|-----:|---------:|-----------:|
| ğŸ¥‡ | **TCN** | **634.74** | 321.82 | 75.00% | **0.469** | 29.6M |
| ğŸ¥ˆ | **WaveNet** | 701.54 | 369.25 | **69.43%** | 0.351 | 32.1M |
| ğŸ¥‰ | **GRU** | 710.60 | 383.77 | 79.53% | 0.335 | 68.0M |
| 4 | Attention | 714.24 | 391.04 | 71.04% | 0.328 | 28.6M |
| 5 | Transformer | 721.62 | 357.90 | 77.46% | 0.314 | 50.8M |
| 6 | LSTM | 724.23 | **359.19** | 74.23% | 0.309 | 40.6M |
| 7 | TFT | 770.05 | 399.55 | 72.30% | 0.219 | 14.2M |
| 8 | ConvLSTM | 886.83 | 523.97 | 84.90% | -0.036 | 13.1M |
| 9 | DenseNN | 943.09 | 638.10 | 81.65% | -0.172 | 14.6M |
| 10 | N-BEATS | 1111.84 | 774.11 | 84.63% | -0.629 | 29.6M |

> **ğŸ“ˆ Best Overall**: TCN achieves the lowest RMSE (634.74) and highest RÂ² (0.469)  
> **ğŸ¯ Best MAPE**: WaveNet has the best percentage error (69.43%)  
> **âš¡ Most Efficient**: TFT achieves competitive results with only 14.2M parameters

<p align="center">
  <img src="outputs/figures/comparison/01_metrics_bars.png" alt="Model Metrics Comparison" width="100%"/>
</p>

---

## ğŸ“¦ Dataset: Multi-Source Agricultural Price Compilation

### Overview

We created a **comprehensive multi-source dataset** by combining **6 different agricultural price datasets** from various sources spanning **32 years (1992-2024)**. This unified dataset provides diverse price patterns across multiple commodities and geographical regions.

### Dataset Sources & Composition

| # | Source | Dataset | Records | Size | Coverage |
|:-:|--------|---------|--------:|-----:|----------|
| 1 | **data.gov.in** | Price_Agriculture_commodities_Week.csv | 23,094 | ~3 MB | India - Weekly commodity prices |
| 2 | **Kaggle** | WFP India Food Prices (csafrit2) | ~15,000 | 1.7 MB | India - UN World Food Programme |
| 3 | **Kaggle** | Vegetables & Fruits Time Series (ramkrijal) | ~8,000 | 1.4 MB | Nepal - Kalimati Market |
| 4 | **Kaggle** | WFP Global Food Prices (jocelyndumlao) | ~50,000 | 228 KB | Global - 80+ countries |
| 5 | **Kaggle** | Commodity Prices 1960-2021 (elmoallistair) | ~3,000 | 5 KB | Global - Historical commodities |
| 6 | **Kaggle** | Crop Price Prediction (varshitanalluri) | ~2,000 | 68 KB | India - Crop yields & prices |

### Data Processing Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RAW DATA SOURCES (6 Datasets)                    â”‚
â”‚    India Weekly + WFP India + Nepal Veg + WFP Global + Historical   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     STANDARDIZATION (prepare_data.py)               â”‚
â”‚  â€¢ Normalize column names (date, price, commodity, source)          â”‚
â”‚  â€¢ Convert dates to datetime format                                 â”‚
â”‚  â€¢ Clean price values (remove nulls, non-numeric)                   â”‚
â”‚  â€¢ Lowercase commodity names                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     COMBINATION & CLEANING                          â”‚
â”‚  â€¢ Concatenate all datasets                                         â”‚
â”‚  â€¢ Remove outliers (1st-99th percentile)                            â”‚
â”‚  â€¢ Combined: ~100,000+ raw records                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     DAILY AGGREGATION                               â”‚
â”‚  â€¢ Group by date                                                    â”‚
â”‚  â€¢ Calculate mean price per day                                     â”‚
â”‚  â€¢ Track record count for each day                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     FINAL DATASET                                   â”‚
â”‚  daily_prices.csv: 7,015 records | 220 KB | 1992-2024               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Final Dataset Statistics

| Property | Value |
|----------|-------|
| **File** | `data/daily_prices.csv` |
| **Records** | 7,015 daily price points |
| **File Size** | 220 KB |
| **Date Range** | January 1992 â†’ January 2024 |
| **Time Span** | 32 years of historical data |
| **Columns** | `date`, `price`, `n_records` |
| **Combined Raw Records** | 42 MB (combined_all.csv) |

### Feature Engineering (10 Features)

During training, we engineer the following features from raw prices:

| Feature | Type | Description |
|---------|------|-------------|
| `price` | Raw | Daily aggregated modal price |
| `log_price` | Transform | Log-transformed price (np.log1p) |
| `pct_change` | Derived | Day-over-day percentage change |
| `ma_7` | Rolling | 7-day moving average |
| `ma_14` | Rolling | 14-day moving average |
| `ma_30` | Rolling | 30-day moving average |
| `std_7` | Rolling | 7-day rolling standard deviation |
| `std_14` | Rolling | 14-day rolling standard deviation |
| `std_30` | Rolling | 30-day rolling standard deviation |
| `momentum` | Derived | Price deviation from MA_7 |

### Data Split

```
Total: 7,015 days
â”œâ”€â”€ Training:   70% (4,910 samples) â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚
â”œâ”€â”€ Validation: 15% (1,052 samples) â”‚â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â”‚
â””â”€â”€ Testing:    15% (1,053 samples) â”‚â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–‘â”‚

Sequence Length: 60 days (lookback window)
Forecast Horizon: 1 day (next-day prediction)
```


---

## ğŸ§  Model Architectures

### Deep Learning Models (10 Architectures, 350M+ Total Parameters)

<details>
<summary><b>ğŸ”µ TCN (Temporal Convolutional Network) - Best Model</b></summary>

```
Architecture:
â”œâ”€â”€ Input Layer (60 timesteps Ã— 10 features)
â”œâ”€â”€ Conv1D Projection (512 filters)
â”œâ”€â”€ 18Ã— Dilated Causal Blocks (dilations: 1,2,4,8,16,32 Ã— 3)
â”‚   â”œâ”€â”€ Conv1D (512 filters, kernel=3, causal padding)
â”‚   â”œâ”€â”€ BatchNormalization
â”‚   â”œâ”€â”€ ReLU Activation
â”‚   â”œâ”€â”€ Dropout (0.1)
â”‚   â””â”€â”€ Residual Connection
â”œâ”€â”€ Global Average Pooling
â”œâ”€â”€ Dense (1024 â†’ 512 â†’ 256 â†’ 64)
â””â”€â”€ Output (1 value)

Parameters: 29,608,321
Key Features: Dilated convolutions, causal padding, residual blocks
```
</details>

<details>
<summary><b>ğŸŸ¢ WaveNet - Audio-Inspired Architecture</b></summary>

```
Architecture:
â”œâ”€â”€ Input Layer (60 timesteps Ã— 10 features)
â”œâ”€â”€ Conv1D Projection (512 filters)
â”œâ”€â”€ 22Ã— Gated Dilated Blocks
â”‚   â”œâ”€â”€ Tanh Gate: Conv1D (512, dilation)
â”‚   â”œâ”€â”€ Sigmoid Gate: Conv1D (512, dilation)
â”‚   â”œâ”€â”€ Gated Activation: Multiply
â”‚   â”œâ”€â”€ Skip Connection (256 filters)
â”‚   â””â”€â”€ Residual Connection (512 filters)
â”œâ”€â”€ Skip Connection Aggregation
â”œâ”€â”€ ReLU â†’ Conv1D (512) â†’ Conv1D (256)
â”œâ”€â”€ Global Average Pooling
â””â”€â”€ Dense (512 â†’ 256 â†’ 64 â†’ 1)

Parameters: 32,066,689
Key Features: Gated activations, skip connections, multi-scale patterns
```
</details>

<details>
<summary><b>ğŸŸ¡ GRU (Gated Recurrent Unit) - Residual Architecture</b></summary>

```
Architecture:
â”œâ”€â”€ Input Layer (60 timesteps Ã— 10 features)
â”œâ”€â”€ Dense Projection (1024 units)
â”œâ”€â”€ 8Ã— Bidirectional GRU Residual Blocks
â”‚   â”œâ”€â”€ Bidirectional GRU (640 units each direction)
â”‚   â”œâ”€â”€ Dropout (0.1)
â”‚   â”œâ”€â”€ Residual Connection (with projection)
â”‚   â””â”€â”€ Layer Normalization
â”œâ”€â”€ Multi-Head Attention (16 heads, key_dim=80)
â”œâ”€â”€ Global Average Pooling
â””â”€â”€ Dense (1024 â†’ 512 â†’ 256 â†’ 128 â†’ 1)

Parameters: 67,968,769
Key Features: Bidirectional processing, residual connections, attention
```
</details>

<details>
<summary><b>ğŸ”´ Transformer - Pre-Norm Architecture</b></summary>

```
Architecture:
â”œâ”€â”€ Input Layer (60 timesteps Ã— 10 features)
â”œâ”€â”€ Dense Embedding (512 dimensions)
â”œâ”€â”€ Learnable Positional Encoding
â”œâ”€â”€ 12Ã— Transformer Blocks (Pre-LayerNorm for stability)
â”‚   â”œâ”€â”€ Pre-LayerNorm
â”‚   â”œâ”€â”€ Multi-Head Self-Attention (16 heads, key_dim=64)
â”‚   â”œâ”€â”€ Residual Connection
â”‚   â”œâ”€â”€ Pre-LayerNorm
â”‚   â”œâ”€â”€ Feed-Forward Network (512 â†’ 2048 â†’ 512)
â”‚   â””â”€â”€ Residual Connection
â”œâ”€â”€ Final Layer Normalization
â”œâ”€â”€ Global Average Pooling
â””â”€â”€ Dense (512 â†’ 256 â†’ 64 â†’ 1)

Parameters: 50,848,129
Key Features: Pre-normalization, gradient stability, self-attention
```
</details>

<details>
<summary><b>ğŸŸ£ LSTM (Long Short-Term Memory) - Multi-Head Attention</b></summary>

```
Architecture:
â”œâ”€â”€ Input Layer (60 timesteps Ã— 10 features)
â”œâ”€â”€ Dense Projection (768 units)
â”œâ”€â”€ 5Ã— Bidirectional LSTM Layers (768 â†’ 640 â†’ 512 â†’ 384 â†’ 256)
â”‚   â”œâ”€â”€ Bidirectional LSTM
â”‚   â”œâ”€â”€ Dropout (0.15)
â”‚   â””â”€â”€ Layer Normalization
â”œâ”€â”€ 2Ã— Multi-Head Attention (16 heads + 8 heads)
â”œâ”€â”€ Global Average Pooling
â””â”€â”€ Dense (1024 â†’ 512 â†’ 256 â†’ 64 â†’ 1)

Parameters: 40,568,065
Key Features: Deep stacked LSTMs, dual attention, bidirectional
```
</details>

<details>
<summary><b>âšª TFT (Temporal Fusion Transformer)</b></summary>

```
Architecture:
â”œâ”€â”€ Input Layer (60 timesteps Ã— 10 features)
â”œâ”€â”€ Variable Selection Network
â”‚   â”œâ”€â”€ Dense (512) + LayerNorm
â”‚   â””â”€â”€ Gating (Sigmoid)
â”œâ”€â”€ 3Ã— Bidirectional LSTM (512 â†’ 384 â†’ 256)
â”œâ”€â”€ 2Ã— Multi-Head Attention (16 heads + 8 heads)
â”œâ”€â”€ Gated Skip Connection
â”œâ”€â”€ Global Average Pooling
â””â”€â”€ Dense (512 â†’ 256 â†’ 64 â†’ 1)

Parameters: 14,206,977
Key Features: Variable selection, gating mechanisms, interpretability
```
</details>

<details>
<summary><b>ğŸŸ¤ Other Models (ConvLSTM, DenseNN, N-BEATS, Attention)</b></summary>

| Model | Architecture Highlights | Parameters |
|-------|------------------------|------------|
| **Attention** | 12Ã— Pure Attention Blocks, Pre-Norm, 12 heads | 28.6M |
| **ConvLSTM** | 6Ã— Conv1D + 4Ã— Bidirectional LSTM hybrid | 13.1M |
| **DenseNN** | 11Ã— Dense layers (2048â†’256), deep MLP | 14.6M |
| **N-BEATS** | 12Ã— Basis expansion blocks, backcast/forecast | 29.6M |

</details>

---

## ğŸ“ˆ Visualization Gallery

### All Model Predictions vs Actual

<p align="center">
  <img src="outputs/figures/comparison/03_predictions_overlay.png" alt="Predictions Overlay" width="100%"/>
</p>

### Performance Scatter Plot (RMSE vs RÂ²)

<p align="center">
  <img src="outputs/figures/comparison/04_performance_scatter.png" alt="Performance Scatter" width="80%"/>
</p>

### Model Size & Training Comparison

<p align="center">
  <img src="outputs/figures/comparison/02_params_epochs.png" alt="Parameters and Epochs" width="100%"/>
</p>

### Error Distribution Analysis

<p align="center">
  <img src="outputs/figures/comparison/07_error_boxplots.png" alt="Error Boxplots" width="100%"/>
</p>

### Training Curves Comparison

<p align="center">
  <img src="outputs/figures/comparison/08_learning_curves.png" alt="Learning Curves" width="100%"/>
</p>

### Performance Heatmap

<p align="center">
  <img src="outputs/figures/comparison/06_heatmap.png" alt="Heatmap" width="70%"/>
</p>

### Efficiency Analysis (RÂ²/Parameters)

<p align="center">
  <img src="outputs/figures/comparison/11_efficiency_plot.png" alt="Efficiency Plot" width="80%"/>
</p>

---

## ğŸ“‚ Individual Model Results

<details>
<summary><b>ğŸ† TCN - Best Performing Model</b></summary>

<table>
<tr>
<td width="50%">
<img src="outputs/figures/tcn/predictions.png" alt="TCN Predictions" width="100%"/>
</td>
<td width="50%">
<img src="outputs/figures/tcn/training_curves.png" alt="TCN Training" width="100%"/>
</td>
</tr>
</table>

<img src="outputs/figures/tcn/error_analysis.png" alt="TCN Error Analysis" width="100%"/>

</details>

<details>
<summary><b>ğŸ¥ˆ WaveNet - Second Best</b></summary>

<table>
<tr>
<td width="50%">
<img src="outputs/figures/wavenet/predictions.png" alt="WaveNet Predictions" width="100%"/>
</td>
<td width="50%">
<img src="outputs/figures/wavenet/training_curves.png" alt="WaveNet Training" width="100%"/>
</td>
</tr>
</table>

<img src="outputs/figures/wavenet/error_analysis.png" alt="WaveNet Error Analysis" width="100%"/>

</details>

<details>
<summary><b>ğŸ¥‰ GRU - Third Best</b></summary>

<table>
<tr>
<td width="50%">
<img src="outputs/figures/gru/predictions.png" alt="GRU Predictions" width="100%"/>
</td>
<td width="50%">
<img src="outputs/figures/gru/training_curves.png" alt="GRU Training" width="100%"/>
</td>
</tr>
</table>

<img src="outputs/figures/gru/error_analysis.png" alt="GRU Error Analysis" width="100%"/>

</details>

<details>
<summary><b>View All 10 Models</b></summary>

| Model | Predictions | Training | Error Analysis |
|-------|-------------|----------|----------------|
| Transformer | [View](outputs/figures/transformer/predictions.png) | [View](outputs/figures/transformer/training_curves.png) | [View](outputs/figures/transformer/error_analysis.png) |
| LSTM | [View](outputs/figures/lstm/predictions.png) | [View](outputs/figures/lstm/training_curves.png) | [View](outputs/figures/lstm/error_analysis.png) |
| Attention | [View](outputs/figures/attention/predictions.png) | [View](outputs/figures/attention/training_curves.png) | [View](outputs/figures/attention/error_analysis.png) |
| TFT | [View](outputs/figures/tft/predictions.png) | [View](outputs/figures/tft/training_curves.png) | [View](outputs/figures/tft/error_analysis.png) |
| ConvLSTM | [View](outputs/figures/convlstm/predictions.png) | [View](outputs/figures/convlstm/training_curves.png) | [View](outputs/figures/convlstm/error_analysis.png) |
| DenseNN | [View](outputs/figures/densenn/predictions.png) | [View](outputs/figures/densenn/training_curves.png) | [View](outputs/figures/densenn/error_analysis.png) |
| N-BEATS | [View](outputs/figures/nbeats/predictions.png) | [View](outputs/figures/nbeats/training_curves.png) | [View](outputs/figures/nbeats/error_analysis.png) |

</details>

---

## ğŸ—ï¸ Project Structure

```
AgriCast-DLWTF/
â”‚
â”œâ”€â”€ ğŸ“‚ src/                          # Source code
â”‚   â”œâ”€â”€ ğŸš€ main.py                   # Main entry point
â”‚   â”œâ”€â”€ âš™ï¸ config.py                 # GPU & model configuration
â”‚   â”œâ”€â”€ ğŸ‹ï¸ train_all.py              # Train all 10 models (MAIN SCRIPT)
â”‚   â”œâ”€â”€ ğŸ”€ train_hybrid.py           # Hybrid ensemble training
â”‚   â”œâ”€â”€ ğŸ“Š combine_all.py            # Result aggregation
â”‚   â”œâ”€â”€ ğŸ“‰ eda.py                    # Exploratory Data Analysis
â”‚   â”œâ”€â”€ ğŸ“ data_loader.py            # Data loading & preprocessing
â”‚   â”œâ”€â”€ ğŸ› ï¸ feature_engineering.py    # Feature pipeline
â”‚   â”œâ”€â”€ ğŸ‹ï¸ training.py               # Training utilities
â”‚   â”œâ”€â”€ ğŸ“ˆ evaluation.py             # Metrics & visualization
â”‚   â”œâ”€â”€ ğŸ”® inference.py              # Model inference
â”‚   â”œâ”€â”€ ğŸ“¦ prepare_data.py           # Data preparation
â”‚   â”œâ”€â”€ â¬‡ï¸ fetch_kaggle_data.py      # Kaggle dataset downloader
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“‚ models/                   # Model architectures
â”‚       â”œâ”€â”€ lstm_model.py            # LSTM with Multi-Head Attention
â”‚       â”œâ”€â”€ gru_model.py             # Bidirectional GRU + Residuals
â”‚       â”œâ”€â”€ transformer_model.py     # 12-layer Pre-Norm Transformer
â”‚       â”œâ”€â”€ tcn_model.py             # Temporal Convolutional Network
â”‚       â”œâ”€â”€ wavenet_model.py         # WaveNet with Gated Activations
â”‚       â”œâ”€â”€ nbeats_model.py          # N-BEATS Basis Expansion
â”‚       â”œâ”€â”€ temporal_fusion.py       # Temporal Fusion Transformer
â”‚       â”œâ”€â”€ ensemble_model.py        # Stacking Meta-Learner
â”‚       â””â”€â”€ base_model.py            # Base interface
â”‚
â”œâ”€â”€ ğŸ“‚ data/                         # Dataset (download via Kaggle)
â”‚   â””â”€â”€ daily_prices.csv
â”‚
â”œâ”€â”€ ğŸ“‚ models/                       # Saved model weights (~6GB)
â”‚   â”œâ”€â”€ tcn.keras
â”‚   â”œâ”€â”€ wavenet.keras
â”‚   â”œâ”€â”€ gru.keras
â”‚   â””â”€â”€ ... (10 models total)
â”‚
â”œâ”€â”€ ğŸ“‚ outputs/
â”‚   â”œâ”€â”€ ğŸ“‚ figures/
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ comparison/           # 12 cross-model comparison charts
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ tcn/                  # TCN visualizations
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ wavenet/              # WaveNet visualizations
â”‚   â”‚   â””â”€â”€ ... (10 model folders)
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“‚ reports/
â”‚       â””â”€â”€ all_models_results.csv   # Complete results table
â”‚
â”œâ”€â”€ ğŸ“‚ notebook/
â”‚   â””â”€â”€ Agricultural_Price_Prediction.ipynb
â”‚
â”œâ”€â”€ ğŸ“„ requirements.txt
â”œâ”€â”€ ğŸ“„ .gitignore
â””â”€â”€ ğŸ“„ README.md
```

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.10+
- NVIDIA GPU with CUDA 12.x (recommended)
- 8GB+ GPU VRAM (RTX 4060 or better)
- 16GB+ System RAM

### 1. Clone & Setup Environment

```bash
# Clone the repository
git clone https://github.com/draxxycodes/AgriCast-DLWTF.git
cd AgriCast-DLWTF

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Download Dataset

```bash
cd src
python fetch_kaggle_data.py
```

Or manually download from [Kaggle](https://www.kaggle.com/) and place in `data/`.

### 3. Train All Models

```bash
cd src
python train_all.py
```

This will:
- âœ… Train all 10 deep learning models with maximum parameters
- âœ… Generate individual visualizations for each model
- âœ… Create 12 comprehensive comparison charts
- âœ… Save results to `outputs/reports/all_models_results.csv`
- â±ï¸ Expected time: 2-4 hours on RTX 4060

### 4. Alternative Training Options

```bash
# Run full pipeline with EDA
python main.py

# Only EDA (no training)
python main.py --mode eda

# Train specific model only
python main.py --mode train --model lstm

# Train for specific commodity
python main.py --commodity Onion

# Train hybrid ensemble (after base models)
python train_hybrid.py
```

---

## ğŸ–¥ï¸ GPU Configuration

### Optimized for NVIDIA RTX 4060

| Feature | Setting | Description |
|---------|---------|-------------|
| **CUDA** | âœ… Enabled | Hardware acceleration |
| **Mixed Precision** | âœ… FP16 | 2x faster training, 50% less memory |
| **XLA JIT** | âœ… Enabled | Optimized tensor operations |
| **Memory Growth** | âœ… Dynamic | Prevents OOM errors |
| **Gradient Clipping** | âœ… clipnorm=1.0 | Prevents NaN gradients |

### Key Optimizations in `train_all.py`

```python
# Model-specific learning rates (prevent NaN for attention models)
MODEL_LR = {
    'Transformer': 5e-5,  # Lower LR for stability
    'Attention': 5e-5,
    'TFT': 8e-5,
    'default': 1e-4
}

# AdamW optimizer with gradient clipping
optimizer = keras.optimizers.AdamW(
    learning_rate=lr,
    clipnorm=1.0,       # Gradient clipping
    weight_decay=1e-5   # L2 regularization
)
```

---

##  Evaluation Metrics

| Metric | Formula | Interpretation |
|--------|---------|----------------|
| **RMSE** | âˆš(Î£(y-Å·)Â²/n) | Penalizes large errors heavily |
| **MAE** | Î£\|y-Å·\|/n | Average absolute error |
| **MAPE** | 100Ã—Î£\|(y-Å·)/y\|/n | Scale-independent percentage |
| **RÂ²** | 1 - SS_res/SS_tot | Explained variance (1.0 = perfect) |

### Why TCN Wins

1. **Causal Convolutions**: Respects temporal order
2. **Dilated Layers**: Captures long-range dependencies efficiently
3. **Parallelizable**: Faster than RNN-based models
4. **Residual Connections**: Enables very deep networks

---

## ğŸ”§ Key Technical Features

### Training Stability
- âœ… Pre-LayerNorm for Transformer/Attention (prevents gradient explosion)
- âœ… Lower learning rates for attention-based models
- âœ… Gradient clipping (clipnorm=1.0)
- âœ… Huber loss (robust to outliers)

### Performance Optimization
- âœ… Mixed precision training (FP16)
- âœ… Early stopping with patience=35
- âœ… Learning rate reduction on plateau
- âœ… Batch size tuning (32)

### Visualization Suite
- âœ… 12 comparison chart types
- âœ… Per-model training curves, predictions, error analysis
- âœ… Radar charts, heatmaps, scatter plots
- âœ… Publication-ready quality (200 DPI)

---

## ğŸ“ Requirements

```txt
tensorflow>=2.15.0
keras>=3.0.0
numpy>=1.24.0
pandas>=2.0.0
scikit-learn>=1.3.0
matplotlib>=3.7.0
seaborn>=0.12.0
```

See [requirements.txt](requirements.txt) for complete list.

---

## ğŸ‘¤ Author

**Deep Learning with TensorFlow Project - CSE 3793**

---

## ğŸ“„ License

This project is for educational purposes as part of the CSE 3793 course.

---

<p align="center">
  Made with â¤ï¸ using TensorFlow & Keras
</p>
